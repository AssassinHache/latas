{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# helper to ensure directory\n",
    "def ensure_dir(p):\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # --- Configuración (ajusta aquí si lo deseas) ---\n",
    "CAPTURE_COUNT = 10  # número de imágenes a capturar\n",
    "INTERVAL = 0.5      # tiempo entre capturas en segundos\n",
    "MODEL_FOLDER = Path('.')            # carpeta donde está el modelo\n",
    "MODEL_FILE_NAME = 'best.pt'      # nombre exacto del modelo que ya verificaste\n",
    "MODEL_PATH = (MODEL_FOLDER / MODEL_FILE_NAME).resolve()\n",
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(f'No se encontró el archivo del modelo en {MODEL_PATH}. Ajusta MODEL_FILE_NAME o mueve el archivo junto al notebook.')\n",
    "print('Usando exclusivamente el modelo:', MODEL_PATH.name)\n",
    "\n",
    "# crear carpeta timestamp para las capturas\n",
    "carpeta = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "ensure_dir(carpeta)\n",
    "\n",
    "# Captura desde la cámara con intervalo configurable\n",
    "cap = cv2.VideoCapture(2)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError('No se pudo abrir la cámara. Verifica que tienes una cámara conectada y permisos.')\n",
    "\n",
    "for i in range(CAPTURE_COUNT):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        nombre_archivo = os.path.join(carpeta, f'imagen_{i+1}.jpg')\n",
    "        cv2.imwrite(nombre_archivo, frame)\n",
    "        print(f'Imagen {i+1}/{CAPTURE_COUNT} guardada -> {nombre_archivo}')\n",
    "    else:\n",
    "        print(f'Frame {i+1} no leído')\n",
    "    time.sleep(INTERVAL)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f'Proceso completado. Imágenes guardadas en: {carpeta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cargar el modelo YOLO (solo archivo local ya verificado) ---\n",
    "backend = None\n",
    "model = None\n",
    "model_path = MODEL_PATH\n",
    "print('Intentando cargar el archivo:', model_path)\n",
    "\n",
    "# 1) Intento con Ultralytics YOLOv8/YOLO11 (misma librería)\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    print('Cargando modelo local con ultralytics.YOLO...')\n",
    "    model = YOLO(str(model_path))\n",
    "    backend = 'ultralytics'\n",
    "except Exception as e_ultra:\n",
    "    print('ultralytics no disponible o carga falló:', e_ultra)\n",
    "\n",
    "# 2) Intento con torch.hub (YOLOv5 custom). Descarga el repo la primera vez.\n",
    "if model is None:\n",
    "    try:\n",
    "        print('Intentando torch.hub (ultralytics/yolov5 custom)...')\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'custom', path=str(model_path), trust_repo=True, source='github', force_reload=False)\n",
    "        backend = 'yolov5_hub'\n",
    "    except Exception as e_hub:\n",
    "        print('torch.hub tampoco pudo cargar el modelo:', e_hub)\n",
    "\n",
    "# 3) Intento manual: cargar checkpoint como módulo PyTorch\n",
    "if model is None:\n",
    "    try:\n",
    "        print('Intentando carga manual con torch.load...')\n",
    "        checkpoint = torch.load(str(model_path), map_location='cpu')\n",
    "        if isinstance(checkpoint, torch.nn.Module):\n",
    "            model = checkpoint\n",
    "            backend = 'torch_module'\n",
    "        elif isinstance(checkpoint, dict) and 'model' in checkpoint:\n",
    "            model = checkpoint['model']\n",
    "            backend = 'torch_state_dict'\n",
    "        else:\n",
    "            raise RuntimeError('Formato del checkpoint no reconocido.')\n",
    "    except Exception as e_manual:\n",
    "        raise RuntimeError('No se pudo cargar el modelo local. Instala \"ultralytics\" o exporta el .pt a un formato compatible.') from e_manual\n",
    "\n",
    "print('Modelo cargado desde archivo local. Backend:', backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predecir sobre las imágenes capturadas ---\n",
    "results_list = []\n",
    "image_paths = sorted([str(p) for p in Path(carpeta).glob('*.jpg')])\n",
    "print('Imágenes encontradas:', image_paths)\n",
    "for img_path in image_paths:\n",
    "    print('Procesando:', img_path)\n",
    "    try:\n",
    "        if backend == 'ultralytics':\n",
    "            res = model(img_path)[0]  # objeto Results de ultralytics\n",
    "            boxes = getattr(res, 'boxes', None)\n",
    "            if boxes is None or len(boxes) == 0:\n",
    "                results_list.append({'image': img_path, 'class': None, 'conf': 0.0})\n",
    "                continue\n",
    "            confidences = boxes.conf.tolist()\n",
    "            classes = boxes.cls.tolist()\n",
    "            top_idx = int(np.argmax(confidences))\n",
    "            top_conf = float(confidences[top_idx])\n",
    "            top_cls = int(classes[top_idx])\n",
    "            names = getattr(model, 'names', {}) if hasattr(model, 'names') else {}\n",
    "            top_name = names.get(top_cls, str(top_cls))\n",
    "        elif backend in {'torch_module','torch_state_dict'}:\n",
    "            model.eval()\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                raise RuntimeError('No se pudo leer la imagen para inferencia.')\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            tensor = torch.from_numpy(img_rgb).float().permute(2,0,1).unsqueeze(0) / 255.0\n",
    "            with torch.no_grad():\n",
    "                raw = model(tensor)\n",
    "            # Suponemos salida estilo YOLO (bs, anchors, (5 + num_cls))\n",
    "            if isinstance(raw, (list, tuple)) and len(raw) > 0:\n",
    "                raw = raw[0]\n",
    "            if raw.dim() == 4:\n",
    "                raw = raw[0]\n",
    "            raw = raw.cpu().numpy().reshape(-1, raw.shape[-1])\n",
    "            boxes = raw[:, :4]\n",
    "            obj_conf = raw[:, 4]\n",
    "            class_scores = raw[:, 5:]\n",
    "            scores = obj_conf[:, None] * class_scores\n",
    "            top_idx = int(np.argmax(scores))\n",
    "            top_conf = float(np.max(scores))\n",
    "            top_cls = int(np.argmax(class_scores[top_idx]))\n",
    "            names = getattr(model, 'names', {}) if hasattr(model, 'names') else {}\n",
    "            top_name = names.get(top_cls, str(top_cls))\n",
    "        else:\n",
    "            raise RuntimeError('Backend no soportado para predicción.')\n",
    "        results_list.append({'image': img_path, 'class': top_name, 'conf': top_conf})\n",
    "        print(f' -> {top_name} ({top_conf:.3f})')\n",
    "    except Exception as e:\n",
    "        print('Error procesando', img_path, e)\n",
    "        results_list.append({'image': img_path, 'class': None, 'conf': 0.0})\n",
    "\n",
    "print('Predicción completada sobre todas las imágenes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agregación y cálculo de índices ---\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "confs = [r['conf'] for r in results_list]\n",
    "classes = [r['class'] or 'None' for r in results_list]\n",
    "\n",
    "# Media aritmética\n",
    "arith_mean = float(np.mean(confs)) if len(confs) > 0 else 0.0\n",
    "# Media geométrica (evitar ceros con eps)\n",
    "eps = 1e-9\n",
    "geom_mean = float(np.exp(np.mean(np.log(np.array(confs) + eps)))) if len(confs) > 0 else 0.0\n",
    "\n",
    "# Determinar clase final: la que tenga mayor promedio de confianza entre las imágenes donde aparece\n",
    "class_scores = {}\n",
    "for r in results_list:\n",
    "    cls = r['class'] or 'None'\n",
    "    class_scores.setdefault(cls, []).append(r['conf'])\n",
    "avg_class_scores = {k: (sum(v) / len(v) if len(v) > 0 else 0.0) for k, v in class_scores.items()}\n",
    "final_class = max(avg_class_scores.items(), key=lambda x: x[1])[0] if len(avg_class_scores) > 0 else None\n",
    "final_conf = avg_class_scores.get(final_class, 0.0) if final_class is not None else 0.0\n",
    "\n",
    "print('Resumen por imagen:')\n",
    "for r in results_list:\n",
    "    print(f\"{Path(r['image']).name}: {r['class']} ({r['conf']:.3f})\")\n",
    "\n",
    "print('\\nPromedios sobre las {} imágenes:'.format(len(confs)))\n",
    "print(f'Arithmetic mean confidence: {arith_mean:.4f}')\n",
    "print(f'Geometric mean confidence: {geom_mean:.4f}')\n",
    "print(f'Final class (mayor avg confidence): {final_class} with {final_conf:.4f}')\n",
    "\n",
    "# Crear DataFrame para análisis posterior\n",
    "results_df = pd.DataFrame(results_list)\n",
    "if not results_df.empty:\n",
    "    results_df['image_name'] = results_df['image'].apply(lambda p: Path(p).name)\n",
    "else:\n",
    "    results_df['image_name'] = []\n",
    "\n",
    "# Guardar resultados en CSV dentro de la carpeta de la captura\n",
    "csv_path = Path(carpeta) / 'results.csv'\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print('Resultados guardados en', csv_path)\n",
    "\n",
    "# Guardar resumen adicional en JSON\n",
    "summary_payload = {\n",
    "    'capture_folder': carpeta,\n",
    "    'image_count': len(results_list),\n",
    "    'final_class': final_class,\n",
    "    'final_confidence': final_conf,\n",
    "    'arithmetic_mean': arith_mean,\n",
    "    'geometric_mean': geom_mean,\n",
    "    'class_scores': avg_class_scores,\n",
    "}\n",
    "json_path = Path(carpeta) / 'results_summary.json'\n",
    "with open(json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary_payload, f, ensure_ascii=False, indent=2)\n",
    "print('Resumen JSON guardado en', json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualizar tabla de resultados ---\n",
    "if 'results_df' not in globals():\n",
    "    raise RuntimeError('Debes ejecutar las celdas anteriores para generar results_df.')\n",
    "display(results_df[['image_name','class','conf']])\n",
    "print('Totales por clase detectada:')\n",
    "print(results_df['class'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filtrar detecciones con confianza mínima ---\n",
    "CONF_THRESHOLD = 0.25\n",
    "if results_df.empty:\n",
    "    high_conf = results_df\n",
    "else:\n",
    "    high_conf = results_df[results_df['conf'] >= CONF_THRESHOLD].copy()\n",
    "print(f'Detecciones con conf >= {CONF_THRESHOLD}: {len(high_conf)}')\n",
    "display(high_conf[['image_name','class','conf']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Estadísticas por clase ---\n",
    "if results_df.empty:\n",
    "    print('No hay predicciones para analizar.')\n",
    "else:\n",
    "    class_summary = (\n",
    "        results_df.groupby('class')['conf']\n",
    "        .agg(['count','mean','max','min'])\n",
    "        .rename(columns={'count':'detections','mean':'avg_conf','max':'max_conf','min':'min_conf'})\n",
    "        .sort_values('avg_conf', ascending=False)\n",
    "    )\n",
    "    display(class_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualización rápida de las confianzas ---\n",
    "if results_df.empty:\n",
    "    print('No hay datos para graficar.')\n",
    "else:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(results_df['image_name'], results_df['conf'], marker='o')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('Confianza')\n",
    "    plt.title('Confianza por imagen (detección más alta)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Función opcional para generar imágenes anotadas ---\n",
    "def generar_anotaciones(origenes, destino=None):\n",
    "    if destino is None:\n",
    "        destino = Path(carpeta) / 'anotadas'\n",
    "    destino = Path(destino)\n",
    "    ensure_dir(destino)\n",
    "    for img_path in origenes:\n",
    "        try:\n",
    "            if backend == 'ultralytics':\n",
    "                res = model(img_path)[0]\n",
    "                annotated = res.plot()\n",
    "            else:\n",
    "                res = model(img_path)\n",
    "                res.render()\n",
    "                annotated = res.ims[0]\n",
    "            salida = destino / f\"annotated_{Path(img_path).name}\"\n",
    "            # OpenCV espera BGR\n",
    "            cv2.imwrite(str(salida), annotated if backend == 'yolov5_hub' else cv2.cvtColor(annotated, cv2.COLOR_RGB2BGR))\n",
    "            print('Guardada anotación en', salida)\n",
    "        except Exception as e:\n",
    "            print('No fue posible anotar', img_path, '->', e)\n",
    "    return destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ejecutar anotaciones y previsualizar una imagen ---\n",
    "if len(image_paths) == 0:\n",
    "    print('No hay imágenes para anotar.')\n",
    "else:\n",
    "    anotadas_dir = generar_anotaciones(image_paths)\n",
    "    muestra = sorted(anotadas_dir.glob('annotated_*.jpg'))\n",
    "    if muestra:\n",
    "        ejemplo = muestra[0]\n",
    "        img = cv2.cvtColor(cv2.imread(str(ejemplo)), cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Ejemplo anotado: {ejemplo.name}')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No se generaron imágenes anotadas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Alternativa de decisión final (mayoría simple) ---\n",
    "if results_df.empty:\n",
    "    print('No hay datos para calcular mayoría.')\n",
    "else:\n",
    "    conteo = Counter(results_df['class'].fillna('None'))\n",
    "    mayor_clase, mayor_val = conteo.most_common(1)[0]\n",
    "    print('Clase más frecuente:', mayor_clase, 'con', mayor_val, 'apariciones de', len(results_df))\n",
    "    print('Distribución completa:')\n",
    "    for clase, total in conteo.items():\n",
    "        print(f' - {clase}: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Limpieza opcional de carpetas antiguas ---\n",
    "import shutil\n",
    "\n",
    "def limpiar_capturas_antiguas(base_path='.', conservar=3):\n",
    "    base = Path(base_path)\n",
    "    capturas = sorted([p for p in base.glob('20????????_??????') if p.is_dir()])\n",
    "    excedente = len(capturas) - conservar\n",
    "    if excedente <= 0:\n",
    "        print('No hay carpetas para eliminar.')\n",
    "        return\n",
    "    for carpeta_antigua in capturas[:excedente]:\n",
    "        try:\n",
    "            shutil.rmtree(carpeta_antigua)\n",
    "            print('Carpeta eliminada:', carpeta_antigua)\n",
    "        except Exception as e:\n",
    "            print('No se pudo eliminar', carpeta_antigua, '->', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prueba rápida de cámara ---\n",
    "def probar_camara(index=0):\n",
    "    prueba = cv2.VideoCapture(index)\n",
    "    if not prueba.isOpened():\n",
    "        print('No se pudo abrir la cámara', index)\n",
    "        return False\n",
    "    ret, frame = prueba.read()\n",
    "    prueba.release()\n",
    "    if not ret:\n",
    "        print('La cámara se abrió pero no entregó frames.')\n",
    "        return False\n",
    "    print('Cámara', index, 'operativa. Resolución:', frame.shape[1], 'x', frame.shape[0])\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Identificar cámaras conectadas ---\n",
    "def listar_camaras(max_indices=5):\n",
    "    disponibles = []\n",
    "    for idx in range(max_indices):\n",
    "        cap = cv2.VideoCapture(idx)\n",
    "        if cap.isOpened():\n",
    "            ret, _ = cap.read()\n",
    "            if ret:\n",
    "                disponibles.append(idx)\n",
    "                print(f\"Cámara {idx}: DISPONIBLE\")\n",
    "            else:\n",
    "                print(f\"Cámara {idx}: abierta pero no entrega frames\")\n",
    "        else:\n",
    "            print(f\"Cámara {idx}: no disponible\")\n",
    "        cap.release()\n",
    "    if not disponibles:\n",
    "        print(\"No se detectaron cámaras operativas en los primeros\", max_indices, \"indices.\")\n",
    "    else:\n",
    "        print(\"Índices utilizables:\", disponibles)\n",
    "\n",
    "# Ejecuta la función para ver las cámaras conectadas\n",
    "listar_camaras(max_indices=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Conexión serial y envío de estados al ESP32 ---\n",
    "# Funciones para listar puertos, seleccionar uno y enviar los estados: 'sana', 'danada', 'defectosa'\n",
    "try:\n",
    "    import serial\n",
    "    import serial.tools.list_ports as list_ports\n",
    "except ImportError:\n",
    "    import sys, subprocess\n",
    "    print('pyserial no instalado. Instalando pyserial...')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pyserial'])\n",
    "    import serial\n",
    "    import serial.tools.list_ports as list_ports\n",
    "import time\n",
    "\n",
    "VALID_STATES = (\"sana\", \"danada\", \"defectosa\")\n",
    "\n",
    "\n",
    "def listar_puertos():\n",
    "    \"\"\"Devuelve lista de puertos serial disponibles y los imprime.\"\"\"\n",
    "    ports = list(list_ports.comports())\n",
    "    dispositivos = []\n",
    "    if not ports:\n",
    "        print(\"No se encontraron puertos serie disponibles.\")\n",
    "        return dispositivos\n",
    "    for i, p in enumerate(ports):\n",
    "        print(f\"{i}: {p.device} - {p.description}\")\n",
    "        dispositivos.append(p.device)\n",
    "    return dispositivos\n",
    "\n",
    "\n",
    "def seleccionar_puerto(preferido: str = None):\n",
    "    \"\"\"Selecciona un puerto. Si 'preferido' está presente, lo devuelve; si no, devuelve el primero encontrado.\"\"\"\n",
    "    puertos = listar_puertos()\n",
    "    if not puertos:\n",
    "        return None\n",
    "    if preferido and preferido in puertos:\n",
    "        print(f\"Usando puerto preferido: {preferido}\")\n",
    "        return preferido\n",
    "    if len(puertos) == 1:\n",
    "        print(f\"Seleccionado puerto: {puertos[0]}\")\n",
    "        return puertos[0]\n",
    "    print(f\"Varios puertos disponibles, se selecciona por defecto: {puertos[0]}\\nPara usar otro, llama seleccionar_puerto('/dev/ttyUSB1')\")\n",
    "    return puertos[0]\n",
    "\n",
    "\n",
    "def send_state(port: str, state: str, baud: int = 115200, timeout: float = 1.0):\n",
    "    \"\"\"Envía un estado por serial y lee una respuesta opcional.\n",
    "\n",
    "    Args:\n",
    "        port: ruta del puerto (por ejemplo '/dev/ttyUSB0')\n",
    "        state: uno de VALID_STATES\n",
    "        baud: velocidad en baudios\n",
    "        timeout: tiempo de espera en segundos\n",
    "\n",
    "    Returns:\n",
    "        La respuesta leída (string) o None si no hay respuesta.\n",
    "    \"\"\"\n",
    "    if state not in VALID_STATES:\n",
    "        raise ValueError(f\"Estado inválido: {state}. Usa uno de: {VALID_STATES}\")\n",
    "    if port is None:\n",
    "        raise RuntimeError(\"Puerto no especificado. Usa seleccionar_puerto() para obtener uno.\")\n",
    "\n",
    "    try:\n",
    "        ser = serial.Serial(port, baudrate=baud, timeout=timeout)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"No se pudo abrir el puerto {port}: {e}\") from e\n",
    "\n",
    "    try:\n",
    "        # Dar tiempo para que el dispositivo se estabilice\n",
    "        time.sleep(0.1)\n",
    "        payload = (state + \"\\n\").encode()\n",
    "        ser.write(payload)\n",
    "        # Intentar leer una línea de respuesta (si el ESP32 responde)\n",
    "        try:\n",
    "            resp = ser.readline().decode(errors='ignore').strip()\n",
    "        except Exception:\n",
    "            resp = None\n",
    "        print(f\"Enviado: '{state}' -> {port} ; Respuesta: '{resp}'\")\n",
    "        return resp\n",
    "    finally:\n",
    "        ser.close()\n",
    "\n",
    "\n",
    "# Función rápida que detecta puerto y envía el estado dado (útil para pruebas)\n",
    "def enviar_estado_auto(state: str, preferido: str = None):\n",
    "    port = seleccionar_puerto(preferido)\n",
    "    if port is None:\n",
    "        raise RuntimeError('No hay puertos serial disponibles para enviar el estado.')\n",
    "    return send_state(port, state)\n",
    "\n",
    "\n",
    "print('Celda de serial cargada. Ejecuta listar_puertos() para ver los puertos.')\n",
    "print('Usar: seleccionar_puerto() o enviar_estado_auto(\"sana\") para pruebas.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Enviar resultado final al ESP32 (usa funciones serial ya definidas)\n",
    "# Esta celda toma 'results_list' o 'results_df', calcula la clase con mayor promedio de confianza\n",
    "# y manda el estado mapeado ('sana','danada','defectosa') al ESP32 usando enviar_estado_auto o send_state.\n",
    "\n",
    "# Mapeo por defecto: ajusta según tus clases reales\n",
    "CLASS_TO_STATE = {\n",
    "    'person': 'danada',\n",
    "    'none': 'sana',\n",
    "    'sana': 'sana',\n",
    "    'defect': 'defectosa',\n",
    "    'defectosa': 'defectosa',\n",
    "    'defectuosa': 'defectosa'\n",
    "}\n",
    "\n",
    "# Si ya sabes el puerto y la placa, configúralos aquí para pruebas automáticas\n",
    "PREFERRED_PORT = '/dev/ttyUSB0'  # cambia si tu puerto es distinto\n",
    "BOARD_NAME = 'ESP32 Dev Module'  # nombre de tu placa (solo informativo)\n",
    "\n",
    "print(f\"Usando puerto preferido: {PREFERRED_PORT} ; Board: {BOARD_NAME}\")\n",
    "\n",
    "def decide_and_send():\n",
    "    import time, traceback\n",
    "    # Determinar final_class/final_conf a partir de results_list o results_df\n",
    "    try:\n",
    "        if 'results_df' in globals() and not results_df.empty:\n",
    "            class_scores = {}\n",
    "            for r in results_list:\n",
    "                cls = (r.get('class') or 'None')\n",
    "                class_scores.setdefault(cls, []).append(r.get('conf', 0.0))\n",
    "            avg_class_scores = {k: (sum(v)/len(v) if len(v)>0 else 0.0) for k,v in class_scores.items()}\n",
    "            final_class = max(avg_class_scores.items(), key=lambda x: x[1])[0] if len(avg_class_scores)>0 else 'None'\n",
    "            final_conf = avg_class_scores.get(final_class, 0.0)\n",
    "        elif 'final_class' in globals():\n",
    "            final_class = final_class\n",
    "            final_conf = globals().get('final_conf', 0.0)\n",
    "        else:\n",
    "            raise RuntimeError('No hay resultados para decidir. Ejecuta las celdas de captura y predicción primero.')\n",
    "\n",
    "        print('Clase final decidida:', final_class, 'conf:', final_conf)\n",
    "        key = str(final_class).lower() if final_class is not None else 'none'\n",
    "        state = CLASS_TO_STATE.get(key)\n",
    "        if state is None:\n",
    "            # Si la clase no está mapeada: si es 'None' -> sana, else -> danada\n",
    "            if key in ('none','nan',''):\n",
    "                state = 'sana'\n",
    "            else:\n",
    "                state = 'danada'\n",
    "        print('Estado que se enviará:', state)\n",
    "\n",
    "        # Enviar usando las funciones disponibles en el notebook\n",
    "        resp = None\n",
    "        if 'enviar_estado_auto' in globals():\n",
    "            try:\n",
    "                # pasar el puerto preferido para forzar uso de /dev/ttyUSB0\n",
    "                resp = enviar_estado_auto(state, preferido=PREFERRED_PORT)\n",
    "                print('Respuesta enviar_estado_auto:', resp)\n",
    "            except Exception as e:\n",
    "                print('Error en enviar_estado_auto:', e)\n",
    "                traceback.print_exc()\n",
    "        else:\n",
    "            # intentar seleccionar puerto y usar send_state (abre/cierra puerto)\n",
    "            try:\n",
    "                port = None\n",
    "                if 'seleccionar_puerto' in globals():\n",
    "                    port = seleccionar_puerto(PREFERRED_PORT)\n",
    "                if port is None:\n",
    "                    print('No se detectó puerto automáticamente. Ejecuta listar_puertos() y usa send_state manualmente.')\n",
    "                else:\n",
    "                    print('Enviando mediante send_state a', port)\n",
    "                    resp = send_state(port, state)\n",
    "                    print('Respuesta send_state:', resp)\n",
    "            except Exception as e:\n",
    "                print('Error al enviar con send_state:', e)\n",
    "                traceback.print_exc()\n",
    "\n",
    "        return state, resp\n",
    "    except Exception as e:\n",
    "        print('Error en decide_and_send:')\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "# Ejecutar la decisión y envío una sola vez (esto no entra al bucle de vídeo)\n",
    "print('Ejecutando decide_and_send() ...')\n",
    "try:\n",
    "    estado_enviado, respuesta = decide_and_send()\n",
    "    print(f'Estado enviado: {estado_enviado} ; Respuesta: {respuesta}')\n",
    "except Exception as e:\n",
    "    print('No se pudo enviar el estado automáticamente:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Detección en vivo desde la cámara ---\n",
    "# if 'model' not in globals() or model is None:\n",
    "#     raise RuntimeError('Primero carga el modelo ejecutando las celdas iniciales.')\n",
    "\n",
    "# if 'backend' not in globals() or backend is None:\n",
    "#     raise RuntimeError('No se detectó backend para el modelo cargado.')\n",
    "\n",
    "# TARGET_WIDTH = 640  # reduce la resolución para acelerar la inferencia\n",
    "# WINDOW_NAME = 'Deteccion en vivo'\n",
    "\n",
    "# cap_live = cv2.VideoCapture(2)\n",
    "# if not cap_live.isOpened():\n",
    "#     raise RuntimeError('No se pudo abrir la cámara para la detección en vivo.')\n",
    "\n",
    "# cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow(WINDOW_NAME, 800, 600)\n",
    "# print(\"Ventana abierta. Presiona 'q' o cierra la ventana para salir.\")\n",
    "# try:\n",
    "#     while True:\n",
    "#         ret, frame = cap_live.read()\n",
    "#         if not ret:\n",
    "#             print('No se recibió frame nuevo; finalizando.')\n",
    "#             break\n",
    "\n",
    "#         frame_for_model = frame\n",
    "#         h, w = frame.shape[:2]\n",
    "#         if w > TARGET_WIDTH:\n",
    "#             scale = TARGET_WIDTH / w\n",
    "#             new_size = (TARGET_WIDTH, int(h * scale))\n",
    "#             frame_for_model = cv2.resize(frame, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#         frame_to_show = frame\n",
    "#         try:\n",
    "#             if backend == 'ultralytics':\n",
    "#                 res = model(frame_for_model, verbose=False)[0]\n",
    "#                 annotated = res.plot()\n",
    "#                 frame_to_show = cv2.resize(annotated, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "#             elif backend == 'yolov5_hub':\n",
    "#                 res = model(frame_for_model)\n",
    "#                 res.render()\n",
    "#                 frame_to_show = cv2.resize(res.ims[0], (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "#         except Exception as live_err:\n",
    "#             print('Error durante la inferencia en vivo:', live_err)\n",
    "#             frame_to_show = frame\n",
    "\n",
    "#         cv2.imshow(WINDOW_NAME, frame_to_show)\n",
    "#         key = cv2.waitKey(1) & 0xFF\n",
    "#         if key == ord('q'):\n",
    "#             break\n",
    "#         if cv2.getWindowProperty(WINDOW_NAME, cv2.WND_PROP_VISIBLE) < 1:\n",
    "#             print('Ventana cerrada por el usuario.')\n",
    "#             break\n",
    "# finally:\n",
    "#     cap_live.release()\n",
    "#     cv2.destroyWindow(WINDOW_NAME)\n",
    "#     print('Detección en vivo finalizada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b9bafe8f1d4403acff4a795c878027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='info', description='Ejecutar celdas ANTERIORES (modo kernel…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Interfaz visual: botón para ejecutar todo y panel de estado ---\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "except Exception as e:\n",
    "    import sys, subprocess\n",
    "    print('ipywidgets no está instalado. Instalando...')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'ipywidgets'])\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "\n",
    "out = widgets.Output(layout={'border': '1px solid #ccc'})\n",
    "run_btn = widgets.Button(description='Ejecutar pipeline (capturar → predecir → enviar)', button_style='primary')\n",
    "run_all_btn = widgets.Button(description='Ejecutar celdas ANTERIORES (modo kernel-only)', button_style='info')\n",
    "\n",
    "\n",
    "def _safe_get(varname, default=None):\n",
    "    return globals().get(varname, default)\n",
    "\n",
    "\n",
    "def on_run(btn):                                                                                                                                                                                                                                                       \n",
    "    from pathlib import Path\n",
    "    import time, traceback, shutil\n",
    "    with out:\n",
    "        clear_output()\n",
    "        print('Iniciando pipeline...')\n",
    "\n",
    "        # Verificar modelo cargado\n",
    "        if _safe_get('model', None) is None or _safe_get('backend', None) is None:\n",
    "            print('Error: no hay modelo cargado. Ejecuta la celda de carga del modelo primero o usa el botón de ejecutar celdas ANTERIORES (kernel-only).')\n",
    "            return\n",
    "\n",
    "        # Parámetros (usar los existentes si están definidos)\n",
    "        CAPTURE_COUNT_LOCAL = _safe_get('CAPTURE_COUNT', 10)\n",
    "        INTERVAL_LOCAL = _safe_get('INTERVAL', 0.5)\n",
    "        CAMERA_INDEX = _safe_get('cap', None)\n",
    "        # si cap no es objeto, usar índice por defecto 2\n",
    "        if isinstance(CAMERA_INDEX, int):\n",
    "            cam_idx = CAMERA_INDEX\n",
    "        else:\n",
    "            cam_idx = 2\n",
    "\n",
    "        # Carpeta de captura\n",
    "        carpeta_local = datetime.now().strftime('%Y%m%d_%H%M%S_ui')\n",
    "        ensure_dir(carpeta_local)\n",
    "        print(f'Carpeta creada: {carpeta_local}')\n",
    "\n",
    "        # Capturar imágenes\n",
    "        cap_widget = cv2.VideoCapture(cam_idx)\n",
    "        if not cap_widget.isOpened():\n",
    "            print(f'No se pudo abrir la cámara index={cam_idx}. Ejecuta listar_camaras() para verificar índices.')\n",
    "            return\n",
    "        for i in range(CAPTURE_COUNT_LOCAL):\n",
    "            ret, frame = cap_widget.read()\n",
    "            if not ret:\n",
    "                print(f'Frame {i+1} no leído')\n",
    "                continue\n",
    "            fname = os.path.join(carpeta_local, f'imagen_{i+1}.jpg')\n",
    "            cv2.imwrite(fname, frame)\n",
    "            print(f'Guardada {fname}')\n",
    "            time.sleep(INTERVAL_LOCAL)\n",
    "        cap_widget.release()\n",
    "\n",
    "        # Inferencia\n",
    "        print('\\nEjecutando inferencia sobre las imágenes capturadas...')\n",
    "        image_paths_local = sorted([str(p) for p in Path(carpeta_local).glob('*.jpg')])\n",
    "        results_local = []\n",
    "        backend_local = _safe_get('backend')\n",
    "        model_local = _safe_get('model')\n",
    "        for img_path in image_paths_local:\n",
    "            try:\n",
    "                if backend_local == 'ultralytics':\n",
    "                    res = model_local(img_path)[0]\n",
    "                    boxes = getattr(res, 'boxes', None)\n",
    "                    if boxes is None or len(boxes) == 0:\n",
    "                        results_local.append({'image': img_path, 'class': None, 'conf': 0.0})\n",
    "                        continue\n",
    "                    confidences = boxes.conf.tolist()\n",
    "                    classes = boxes.cls.tolist()\n",
    "                    top_idx = int(np.argmax(confidences))\n",
    "                    top_conf = float(confidences[top_idx])\n",
    "                    top_cls = int(classes[top_idx])\n",
    "                    names = getattr(model_local, 'names', {}) if hasattr(model_local, 'names') else {}\n",
    "                    top_name = names.get(top_cls, str(top_cls))\n",
    "                else:\n",
    "                    # intentar usar la lógica existente simplificada\n",
    "                    model_local.eval()\n",
    "                    img = cv2.imread(img_path)\n",
    "                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    tensor = torch.from_numpy(img_rgb).float().permute(2,0,1).unsqueeze(0) / 255.0\n",
    "                    with torch.no_grad():\n",
    "                        raw = model_local(tensor)\n",
    "                    if isinstance(raw, (list, tuple)) and len(raw) > 0:\n",
    "                        raw = raw[0]\n",
    "                    if hasattr(raw, 'dim') and raw.dim() == 4:\n",
    "                        raw = raw[0]\n",
    "                    raw = raw.cpu().numpy().reshape(-1, raw.shape[-1])\n",
    "                    obj_conf = raw[:,4]\n",
    "                    class_scores = raw[:,5:]\n",
    "                    scores = obj_conf[:, None] * class_scores\n",
    "                    top_idx = int(np.argmax(scores))\n",
    "                    top_conf = float(np.max(scores))\n",
    "                    top_cls = int(np.argmax(class_scores[top_idx]))\n",
    "                    names = getattr(model_local, 'names', {}) if hasattr(model_local, 'names') else {}\n",
    "                    top_name = names.get(top_cls, str(top_cls))\n",
    "                results_local.append({'image': img_path, 'class': top_name, 'conf': top_conf})\n",
    "                print(f' -> {Path(img_path).name}: {top_name} ({top_conf:.3f})')\n",
    "            except Exception as e:\n",
    "                print('Error en inferencia:', e)\n",
    "                traceback.print_exc()\n",
    "                results_local.append({'image': img_path, 'class': None, 'conf': 0.0})\n",
    "\n",
    "        # Generar y guardar imágenes anotadas (si es posible)\n",
    "        try:\n",
    "            anotadas_dir = Path(carpeta_local) / 'anotadas'\n",
    "            ensure_dir(anotadas_dir)\n",
    "            print('\\nGenerando imágenes anotadas en:', anotadas_dir)\n",
    "            for img_path in image_paths_local:\n",
    "                try:\n",
    "                    if backend_local == 'ultralytics':\n",
    "                        res = model_local(img_path)[0]\n",
    "                        annotated = res.plot()\n",
    "                        salida = anotadas_dir / f\"annotated_{Path(img_path).name}\"\n",
    "                        # res.plot() devuelve RGB\n",
    "                        cv2.imwrite(str(salida), cv2.cvtColor(annotated, cv2.COLOR_RGB2BGR))\n",
    "                    elif backend_local == 'yolov5_hub':\n",
    "                        res = model_local(img_path)\n",
    "                        res.render()\n",
    "                        annotated = res.ims[0]\n",
    "                        salida = anotadas_dir / f\"annotated_{Path(img_path).name}\"\n",
    "                        # ultralytics/v5 differences handled similarly to generar_anotaciones\n",
    "                        cv2.imwrite(str(salida), annotated if backend_local == 'yolov5_hub' else cv2.cvtColor(annotated, cv2.COLOR_RGB2BGR))\n",
    "                    else:\n",
    "                        # Fallback: copiar la original si no podemos anotar\n",
    "                        salida = anotadas_dir / f\"annotated_{Path(img_path).name}\"\n",
    "                        shutil.copy(img_path, str(salida))\n",
    "                    print('Guardada anotada:', salida)\n",
    "                except Exception as e:\n",
    "                    print('No fue posible anotar', img_path, '->', e)\n",
    "        except Exception as e:\n",
    "            print('Error generando anotadas:', e)\n",
    "\n",
    "        # Agregación\n",
    "        confs_local = [r['conf'] for r in results_local]\n",
    "        class_scores_local = {}\n",
    "        for r in results_local:\n",
    "            cls = r['class'] or 'None'\n",
    "            class_scores_local.setdefault(cls, []).append(r['conf'])\n",
    "        avg_class_scores_local = {k: (sum(v)/len(v) if len(v)>0 else 0.0) for k,v in class_scores_local.items()}\n",
    "        final_class_local = max(avg_class_scores_local.items(), key=lambda x: x[1])[0] if len(avg_class_scores_local)>0 else 'None'\n",
    "        final_conf_local = avg_class_scores_local.get(final_class_local, 0.0)\n",
    "        print('\\nDecisión final:', final_class_local, f'conf={final_conf_local:.3f}')\n",
    "\n",
    "        # Mostrar tabla resumida\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            df_local = pd.DataFrame(results_local)\n",
    "            display(df_local[['image','class','conf']])\n",
    "        except Exception:\n",
    "            df_local = None\n",
    "\n",
    "        # Guardar resultados globales para inspección\n",
    "        try:\n",
    "            globals().update({\n",
    "                'results_list': results_local,\n",
    "                'results_df': df_local if df_local is not None else pd.DataFrame(results_local),\n",
    "                'final_class': final_class_local,\n",
    "                'final_conf': final_conf_local,\n",
    "                'carpeta': carpeta_local\n",
    "            })\n",
    "            print('Variables results_list, results_df, final_class, final_conf y carpeta guardadas en el kernel.')\n",
    "        except Exception as e:\n",
    "            print('No fue posible guardar variables globales:', e)\n",
    "\n",
    "        # Mapear a estado y enviar (si existe la función serial)\n",
    "        key_local = str(final_class_local).lower() if final_class_local is not None else 'none'\n",
    "        CLASS_TO_STATE_LOCAL = _safe_get('CLASS_TO_STATE', { 'person':'danada','none':'sana' })\n",
    "        state_local = CLASS_TO_STATE_LOCAL.get(key_local)\n",
    "        if state_local is None:\n",
    "            state_local = 'sana' if key_local in ('none','nan','') else 'danada'\n",
    "        print('Estado determinado:', state_local)\n",
    "        if 'enviar_estado_auto' in globals():\n",
    "            try:\n",
    "                resp_local = enviar_estado_auto(state_local, preferido=_safe_get('PREFERRED_PORT', None))\n",
    "                print('Respuesta del dispositivo:', resp_local)\n",
    "            except Exception as e:\n",
    "                print('Error enviando por serial:', e)\n",
    "                traceback.print_exc()\n",
    "        else:\n",
    "            print('Función serial no disponible. Ejecuta la celda de serial primero.')\n",
    "\n",
    "\n",
    "def on_run_all(btn):\n",
    "    \"\"\"Modo kernel-only: cargar modelo + serial si faltan y ejecutar pipeline en el kernel.\n",
    "    Esto evita depender del front-end JS (útil en VS Code / JupyterLab).\"\"\"\n",
    "    import traceback, subprocess, sys\n",
    "    with out:\n",
    "        clear_output()\n",
    "        print('Modo kernel-only: verificando y cargando dependencias...')\n",
    "\n",
    "        # 1) Asegurar que MODEL_PATH esté definido\n",
    "        MODEL_PATH_LOCAL = _safe_get('MODEL_PATH', None)\n",
    "        if MODEL_PATH_LOCAL is None:\n",
    "            print('ERROR: MODEL_PATH no está definido en el kernel. Define MODEL_PATH o ejecuta la celda de configuración antes.')\n",
    "            return\n",
    "\n",
    "        # 2) Cargar modelo si hace falta\n",
    "        if _safe_get('model', None) is None or _safe_get('backend', None) is None:\n",
    "            print('Modelo no cargado: intentando carga desde', MODEL_PATH_LOCAL)\n",
    "            try:\n",
    "                # intentar ultralytics\n",
    "                try:\n",
    "                    from ultralytics import YOLO\n",
    "                    m = YOLO(str(MODEL_PATH_LOCAL))\n",
    "                    globals()['model'] = m\n",
    "                    globals()['backend'] = 'ultralytics'\n",
    "                    print('Modelo cargado con ultralytics.')\n",
    "                except Exception as e1:\n",
    "                    print('ultralytics no disponible o falló:', e1)\n",
    "                    # intentar torch.hub\n",
    "                    try:\n",
    "                        print('Intentando torch.hub...')\n",
    "                        m = torch.hub.load('ultralytics/yolov5', 'custom', path=str(MODEL_PATH_LOCAL), trust_repo=True, source='github', force_reload=False)\n",
    "                        globals()['model'] = m\n",
    "                        globals()['backend'] = 'yolov5_hub'\n",
    "                        print('Modelo cargado con torch.hub (yolov5).')\n",
    "                    except Exception as e2:\n",
    "                        print('torch.hub falló:', e2)\n",
    "                        # intentar torch.load\n",
    "                        try:\n",
    "                            ckpt = torch.load(str(MODEL_PATH_LOCAL), map_location='cpu')\n",
    "                            if isinstance(ckpt, torch.nn.Module):\n",
    "                                globals()['model'] = ckpt\n",
    "                                globals()['backend'] = 'torch_module'\n",
    "                            elif isinstance(ckpt, dict) and 'model' in ckpt:\n",
    "                                globals()['model'] = ckpt['model']\n",
    "                                globals()['backend'] = 'torch_state_dict'\n",
    "                            else:\n",
    "                                raise RuntimeError('Formato del checkpoint no reconocido.')\n",
    "                            print('Modelo cargado con torch.load.')\n",
    "                        except Exception as e3:\n",
    "                            print('No fue posible cargar el modelo:', e3)\n",
    "                            traceback.print_exc()\n",
    "                            return\n",
    "            except Exception as e:\n",
    "                print('Error durante la carga del modelo:', e)\n",
    "                traceback.print_exc()\n",
    "                return\n",
    "        else:\n",
    "            print('Modelo ya cargado en el kernel. Backend:', _safe_get('backend'))\n",
    "\n",
    "        # 3) Asegurar funciones de serial\n",
    "        if 'enviar_estado_auto' not in globals() or 'send_state' not in globals():\n",
    "            print('Funciones serial no detectadas: definiendo helpers mínimos (pyserial).')\n",
    "            try:\n",
    "                import serial, serial.tools.list_ports as list_ports\n",
    "            except Exception:\n",
    "                print('pyserial no encontrado. Instalando...')\n",
    "                subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pyserial'])\n",
    "                import serial, serial.tools.list_ports as list_ports\n",
    "\n",
    "            def listar_puertos_min():\n",
    "                ports = list(list_ports.comports())\n",
    "                return [p.device for p in ports]\n",
    "\n",
    "            def seleccionar_puerto_min(preferido: str = None):\n",
    "                ps = listar_puertos_min()\n",
    "                if not ps:\n",
    "                    return None\n",
    "                if preferido and preferido in ps:\n",
    "                    return preferido\n",
    "                return ps[0]\n",
    "\n",
    "            def send_state_min(port: str, state: str, baud: int = 115200, timeout: float = 1.0):\n",
    "                if port is None:\n",
    "                    raise RuntimeError('Puerto no especificado para send_state_min')\n",
    "                ser = serial.Serial(port, baudrate=baud, timeout=timeout)\n",
    "                try:\n",
    "                    time.sleep(0.1)\n",
    "                    ser.write((state + '\\n').encode())\n",
    "                    try:\n",
    "                        resp = ser.readline().decode(errors='ignore').strip()\n",
    "                    except Exception:\n",
    "                        resp = None\n",
    "                    print(f\"Enviado: '{state}' -> {port} ; Respuesta: '{resp}'\")\n",
    "                    return resp\n",
    "                finally:\n",
    "                    ser.close()\n",
    "\n",
    "            def enviar_estado_auto_min(state: str, preferido: str = None):\n",
    "                port = seleccionar_puerto_min(preferido)\n",
    "                if port is None:\n",
    "                    raise RuntimeError('No se encontraron puertos serie para enviar el estado.')\n",
    "                return send_state_min(port, state)\n",
    "\n",
    "            globals().update({\n",
    "                'listar_puertos': listar_puertos_min,\n",
    "                'seleccionar_puerto': seleccionar_puerto_min,\n",
    "                'send_state': send_state_min,\n",
    "                'enviar_estado_auto': enviar_estado_auto_min\n",
    "            })\n",
    "            print('Helpers serial mínimos definidos.')\n",
    "        else:\n",
    "            print('Funciones serial ya definidas en el kernel.')\n",
    "\n",
    "        # 4) Ejecutar pipeline (llamar a on_run) para capturar → predecir → agregar → enviar\n",
    "        print('\\nEjecutando pipeline de captura/predicción/envío en modo kernel-only...')\n",
    "        try:\n",
    "            on_run(None)\n",
    "        except Exception as e:\n",
    "            print('Error ejecutando pipeline en modo kernel-only:', e)\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "run_btn.on_click(on_run)\n",
    "run_all_btn.on_click(on_run_all)\n",
    "\n",
    "# Mostrar los botones y el panel de salida\n",
    "display(widgets.VBox([widgets.HBox([run_all_btn, run_btn]), out]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captura_imagenes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
